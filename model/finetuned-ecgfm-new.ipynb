{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee6d3b9",
   "metadata": {
    "papermill": {
     "duration": 0.002159,
     "end_time": "2025-11-29T14:58:07.804729",
     "exception": false,
     "start_time": "2025-11-29T14:58:07.802570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ECG-FM Finetuning V38: Domain Adaptation & Robustness\n",
    "\n",
    "Phi√™n b·∫£n n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ **\"Lead Mismatch\"** (S·ª± kh√°c bi·ªát gi·ªØa Lead II b·ªánh vi·ªán v√† Lead I Polar H10) th√¥ng qua k·ªπ thu·∫≠t Augmentation.\n",
    "\n",
    "**T√≠nh nƒÉng n·ªïi b·∫≠t:**\n",
    "1.  **Signal Augmentation:** T·ª± ƒë·ªông co gi√£n bi√™n ƒë·ªô v√† th·ªùi gian ng·∫´u nhi√™n trong l√∫c train ƒë·ªÉ model h·ªçc ƒë∆∞·ª£c t√≠nh b·∫•t bi·∫øn (Invariance).\n",
    "2.  **Weighted Loss:** C√¢n b·∫±ng l·∫°i s·ª± ch√∫ √Ω c·ªßa model v√†o c√°c l·ªõp b·ªánh hi·∫øm (STE, STD).\n",
    "3.  **Support Polar Data:** T·ªëi ∆∞u ƒë·ªÉ h·ªçc t·ª´ d·ªØ li·ªáu h·ªón h·ª£p (Dataset g·ªëc + D·ªØ li·ªáu Polar user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3660f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T14:58:07.809101Z",
     "iopub.status.busy": "2025-11-29T14:58:07.808793Z",
     "iopub.status.idle": "2025-11-29T15:02:15.681905Z",
     "shell.execute_reply": "2025-11-29T15:02:15.680904Z"
    },
    "papermill": {
     "duration": 247.876888,
     "end_time": "2025-11-29T15:02:15.683425",
     "exception": false,
     "start_time": "2025-11-29T14:58:07.806537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Setup Environment\n",
    "!rm -rf fairseq fairseq-signals bin microroot py39_env\n",
    "\n",
    "print(\"‚è≥ Installing Micromamba...\")\n",
    "!curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xj bin/micromamba\n",
    "\n",
    "!./bin/micromamba create -r microroot -n ecg_env -c pytorch -c nvidia -c conda-forge \\\n",
    "    python=3.9 \\\n",
    "    pytorch torchvision torchaudio pytorch-cuda=12.1 \\\n",
    "    -y\n",
    "print(\"‚úÖ Environment Created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc898f64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T15:02:15.866085Z",
     "iopub.status.busy": "2025-11-29T15:02:15.865464Z",
     "iopub.status.idle": "2025-11-29T15:03:07.188686Z",
     "shell.execute_reply": "2025-11-29T15:03:07.187965Z"
    },
    "papermill": {
     "duration": 51.509501,
     "end_time": "2025-11-29T15:03:07.282931",
     "exception": false,
     "start_time": "2025-11-29T15:02:15.773430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "./bin/micromamba run -r microroot -n ecg_env pip install \\\n",
    "    \"transformers==4.30.0\" \"accelerate>=0.20.0\" \\\n",
    "    pandas scipy wfdb pyarrow scikit-learn tqdm \\\n",
    "    hydra-core omegaconf bitarray soundfile matplotlib \\\n",
    "    sacrebleu portalocker regex tensorboardX \"antlr4-python3-runtime==4.8\"\n",
    "\n",
    "git clone https://github.com/facebookresearch/fairseq.git\n",
    "cd fairseq; git checkout v0.12.2; cd ..\n",
    "git clone https://github.com/Jwoo5/fairseq-signals.git\n",
    "\n",
    "echo \"‚úÖ Setup Complete.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c7532",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T15:03:07.557720Z",
     "iopub.status.busy": "2025-11-29T15:03:07.557434Z",
     "iopub.status.idle": "2025-11-29T15:03:07.565972Z",
     "shell.execute_reply": "2025-11-29T15:03:07.565314Z"
    },
    "papermill": {
     "duration": 0.192222,
     "end_time": "2025-11-29T15:03:07.567141",
     "exception": false,
     "start_time": "2025-11-29T15:03:07.374919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile train_robust.py\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# --- ENV SETUP ---\n",
    "os.environ[\"MPLBACKEND\"] = \"Agg\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "cwd = os.getcwd()\n",
    "sys.path.insert(0, os.path.join(cwd, \"fairseq\"))\n",
    "sys.path.insert(0, os.path.join(cwd, \"fairseq-signals\"))\n",
    "\n",
    "try:\n",
    "    from fairseq_signals.models.wav2vec.wav2vec2_cmsc_rlm import Wav2Vec2CMSCRLMModel, Wav2Vec2CMSCRLMConfig\n",
    "except:\n",
    "    try:\n",
    "        from fairseq_signals.models.ecg_transformer import ECGTransformerModel as Wav2Vec2CMSCRLMModel\n",
    "        from fairseq_signals.models.ecg_transformer import ECGTransformerConfig as Wav2Vec2CMSCRLMConfig\n",
    "    except: sys.exit(1)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CSV_PATH = \"/kaggle/input/dataset-multilabel-v3/dataset_multilabel_500hz/labels.csv\"\n",
    "DATA_DIR = \"/kaggle/input/dataset-multilabel-v3/dataset_multilabel_500hz/data\"\n",
    "PRETRAINED_PATH = \"/kaggle/input/ecg-fm-pretrained-v2/pytorch/default/1/mimic_iv_ecg_physionet_pretrained.pt\"\n",
    "SAVE_DIR = \"/kaggle/working\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "LR = 3e-5\n",
    "TARGET_LEN = 5000\n",
    "\n",
    "# --- ROBUST DATASET (AUGMENTATION) ---\n",
    "class RobustECGDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, split='train'):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.data = df[df['split'] == split].reset_index(drop=True)\n",
    "        \n",
    "        all_labels = []\n",
    "        for x in df['labels'].dropna().astype(str):\n",
    "            all_labels.extend(x.split(';'))\n",
    "        self.classes = sorted(list(set(all_labels)))\n",
    "        self.c2i = {c: i for i, c in enumerate(self.classes)}\n",
    "        print(f\"[{split.upper()}] Samples: {len(self.data)} | Classes: {len(self.classes)}\")\n",
    "        \n",
    "    def get_pos_weights(self):\n",
    "        \"\"\"T√≠nh tr·ªçng s·ªë ph·∫°t cho c√°c l·ªõp hi·∫øm\"\"\"\n",
    "        counts = np.zeros(len(self.classes))\n",
    "        for labels in self.data['labels'].dropna():\n",
    "            for l in str(labels).split(';'):\n",
    "                if l in self.c2i: counts[self.c2i[l]] += 1\n",
    "        \n",
    "        total = len(self.data)\n",
    "        weights = (total - counts) / (counts + 1e-6)\n",
    "        return torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self): return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        try:\n",
    "            path = os.path.join(self.root_dir, row['filename'])\n",
    "            ecg = np.load(path).astype(np.float32)\n",
    "            ecg = np.nan_to_num(ecg)\n",
    "            \n",
    "            # === AUGMENTATION (Ch·ªâ train) ===\n",
    "            if self.split == 'train':\n",
    "                # 1. Random Amplitude (Tr·ªã l·ªói Polar bi√™n ƒë·ªô th·∫•p)\n",
    "                if random.random() > 0.3:\n",
    "                    scale = random.uniform(0.7, 1.4)\n",
    "                    ecg = ecg * scale\n",
    "                \n",
    "                # 2. Time Warp (Tr·ªã l·ªói RBBB gi·∫£ do ƒë·ªô r·ªông s√≥ng)\n",
    "                if random.random() > 0.5:\n",
    "                    factor = random.uniform(0.9, 1.1)\n",
    "                    new_len = int(len(ecg) * factor)\n",
    "                    ecg = signal.resample(ecg, new_len)\n",
    "                \n",
    "                # 3. Add Noise (Tr·ªã nhi·ªÖu sensor)\n",
    "                if random.random() > 0.5:\n",
    "                    noise = np.random.normal(0, 0.02, ecg.shape)\n",
    "                    ecg = ecg + noise\n",
    "            # ================================\n",
    "\n",
    "            # Normalize\n",
    "            if np.std(ecg) > 1e-6:\n",
    "                ecg = (ecg - np.mean(ecg)) / np.std(ecg)\n",
    "            else: ecg = np.zeros_like(ecg)\n",
    "            \n",
    "            # Fix Length (C·∫Øt/ƒê·ªám l·∫°i sau khi time warp)\n",
    "            if len(ecg) < TARGET_LEN:\n",
    "                ecg = np.pad(ecg, (0, TARGET_LEN - len(ecg)), 'constant')\n",
    "            else:\n",
    "                # Random Crop khi train gi√∫p h·ªçc nhi·ªÅu ph·∫ßn c·ªßa s√≥ng\n",
    "                if self.split == 'train':\n",
    "                    start = random.randint(0, len(ecg) - TARGET_LEN)\n",
    "                    ecg = ecg[start : start + TARGET_LEN]\n",
    "                else:\n",
    "                    ecg = ecg[:TARGET_LEN]\n",
    "\n",
    "            x = torch.tensor(np.tile(ecg, (12, 1)), dtype=torch.float32)\n",
    "            y = torch.zeros(len(self.classes), dtype=torch.float32)\n",
    "            if pd.notna(row['labels']):\n",
    "                for l in str(row['labels']).split(';'):\n",
    "                    if l in self.c2i: y[self.c2i[l]] = 1.0\n",
    "            return x, y\n",
    "        except: \n",
    "            return torch.zeros((12, TARGET_LEN), dtype=torch.float32), torch.zeros(len(self.classes), dtype=torch.float32)\n",
    "\n",
    "# --- MODEL ---\n",
    "class ECGFM_MultiLabel(nn.Module):\n",
    "    def __init__(self, pt_path, n_cls):\n",
    "        super().__init__()\n",
    "        cfg = Wav2Vec2CMSCRLMConfig()\n",
    "        if hasattr(cfg, 'model'): model_cfg = cfg.model\n",
    "        else: model_cfg = cfg\n",
    "        model_cfg.encoder_embed_dim = 768\n",
    "        model_cfg.conv_feature_layers = \"[(256, 2, 2)] * 4\"\n",
    "        self.enc = Wav2Vec2CMSCRLMModel(model_cfg)\n",
    "        if pt_path and os.path.exists(pt_path):\n",
    "            state = torch.load(pt_path, map_location=\"cpu\")\n",
    "            if \"model\" in state: state = state[\"model\"]\n",
    "            s = {k.replace(\"module.\", \"\"): v for k, v in state.items()}\n",
    "            self.enc.load_state_dict(s, strict=False)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(768, 256), nn.ReLU(), nn.Dropout(0.4), nn.Linear(256, n_cls)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.head(self.enc(source=x, padding_mask=None, mask=False)['x'].mean(dim=1))\n",
    "\n",
    "# --- MAIN ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(CSV_PATH): sys.exit(0)\n",
    "    \n",
    "    train_ds = RobustECGDataset(CSV_PATH, DATA_DIR, 'train')\n",
    "    val_ds = RobustECGDataset(CSV_PATH, DATA_DIR, 'val')\n",
    "    test_ds = RobustECGDataset(CSV_PATH, DATA_DIR, 'test')\n",
    "    \n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # WEIGHTED LOSS\n",
    "    pos_weight = train_ds.get_pos_weights().to(DEVICE)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    \n",
    "    model = ECGFM_MultiLabel(PRETRAINED_PATH, len(train_ds.classes)).to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "    \n",
    "    print(\"üöÄ Training V38 (Robust Mode)...\")\n",
    "    best_f1 = 0.0\n",
    "    \n",
    "    for ep in range(EPOCHS):\n",
    "        model.train()\n",
    "        loss_sum = 0\n",
    "        for x, y in tqdm(train_dl, desc=f\"Ep {ep+1}\"):\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "            \n",
    "        # Val\n",
    "        model.eval()\n",
    "        all_y, all_p = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_dl:\n",
    "                probs = torch.sigmoid(model(x.to(DEVICE))).cpu().numpy()\n",
    "                all_y.append(y.numpy()); all_p.append(probs)\n",
    "        \n",
    "        all_y = np.concatenate(all_y); all_p = np.concatenate(all_p)\n",
    "        curr_f1 = f1_score(all_y, (all_p > 0.5).astype(int), average='macro', zero_division=0)\n",
    "        print(f\"   Loss: {loss_sum/len(train_dl):.4f} | Val F1: {curr_f1:.4f}\")\n",
    "        scheduler.step(curr_f1)\n",
    "        \n",
    "        if curr_f1 > best_f1:\n",
    "            best_f1 = curr_f1\n",
    "            torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"ecg_fm_best.pth\"))\n",
    "            \n",
    "    # TEST\n",
    "    print(\"\\nüß™ TESTING PHASE (Sensitive Thresholds)\")\n",
    "    model.load_state_dict(torch.load(os.path.join(SAVE_DIR, \"ecg_fm_best.pth\")))\n",
    "    model.eval()\n",
    "    y_true, y_prob = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(test_dl):\n",
    "            probs = torch.sigmoid(model(x.to(DEVICE))).cpu().numpy()\n",
    "            y_true.append(y.numpy()); y_prob.append(probs)\n",
    "            \n",
    "    y_true = np.concatenate(y_true); y_prob = np.concatenate(y_prob)\n",
    "    \n",
    "    print(f\"{'CLASS':<10} | {'THRESHOLD':<10} | {'PRECISION':<10} | {'RECALL':<10} | {'F1':<10}\")\n",
    "    print(\"-\"*60)\n",
    "    for i, cls in enumerate(train_ds.classes):\n",
    "        thresh = 0.3 if cls in ['STE', 'STD', 'LBBB', 'AFIB'] else 0.5\n",
    "        y_pred = (y_prob[:, i] > thresh).astype(int)\n",
    "        report = classification_report(y_true[:, i], y_pred, output_dict=True, zero_division=0)\n",
    "        s = report['1.0']\n",
    "        print(f\"{cls:<10} | {thresh:<10} | {s['precision']:.2f}       | {s['recall']:.2f}     | {s['f1-score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b08b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T15:03:07.756903Z",
     "iopub.status.busy": "2025-11-29T15:03:07.756323Z",
     "iopub.status.idle": "2025-11-29T15:03:36.025060Z",
     "shell.execute_reply": "2025-11-29T15:03:36.024297Z"
    },
    "papermill": {
     "duration": 28.36792,
     "end_time": "2025-11-29T15:03:36.026588",
     "exception": false,
     "start_time": "2025-11-29T15:03:07.658668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!./bin/micromamba run -r microroot -n ecg_env python train_robust.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8831093,
     "sourceId": 13861883,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8870914,
     "sourceId": 13921239,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 513780,
     "modelInstanceId": 498520,
     "sourceId": 659257,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 332.651272,
   "end_time": "2025-11-29T15:03:36.436696",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-29T14:58:03.785424",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
